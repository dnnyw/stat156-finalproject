{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81ac17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "NOAA_dir = current_dir + r'\\NOAA Weather Data'\n",
    "EPA_dir = current_dir + r'\\EPA Ozone Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69fa5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(NOAA_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce64711",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(EPA_dir + r'\\Raw EPA Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8815d7d",
   "metadata": {},
   "source": [
    "# Getting Station Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers2 = [\"StationId\", \"lat\", \"long\", \"elev\", \"name\", \"a\", \"b\"]\n",
    "\n",
    "# station_codes = pd.read_csv(NOAA_dir + r'\\ghcnd-stations.csv', names = headers2)\n",
    "\n",
    "# US_only_station = station_codes[station_codes[\"StationId\"].apply(lambda x: x[0:2]) == \"US\"]\n",
    "\n",
    "# US_only_station.to_csv(\"us_station_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_station_codes = pd.read_csv(NOAA_dir + r\"\\us_station_codes.csv\", index_col = 0).drop(columns = [\"a\", \"b\"])\n",
    "us_station_codes.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa145d",
   "metadata": {},
   "source": [
    "# Cleaning Weather Data and Joining Station Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA_files = ['1989.csv.gz',\n",
    "         '1990.csv.gz',\n",
    "         '1991.csv.gz',\n",
    "         '1992.csv.gz',\n",
    "         '1993.csv.gz',\n",
    "         '1994.csv.gz',\n",
    "         '1995.csv.gz',\n",
    "         '1996.csv.gz',\n",
    "         '1997.csv.gz',\n",
    "         '1998.csv.gz',\n",
    "         '1999.csv.gz',\n",
    "         '2000.csv.gz',\n",
    "         '2001.csv.gz',\n",
    "         '2002.csv.gz',\n",
    "         '2003.csv.gz',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"StationId\", \"Date\", \"Measurement\", \"Value\", \"Flag1\", \"Flag2\", \"Flag3\", \"Flag4\"]\n",
    "desired_measurements = [\"TMAX\", \"TMIN\", \"PRCP\", \"SNOW\", \"SNWD\"]\n",
    "\n",
    "for file in NOAA_files: \n",
    "    if file[0:4] + \"_filtered.csv\" in os.listdir(NOAA_dir):\n",
    "        print(\"skipping \"+ file + \", already converted\")\n",
    "        continue\n",
    "    else: \n",
    "        print(\"working on \" + file)\n",
    "        temp = pd.read_csv(NOAA_dir + \"\\\\\" + file, names = headers)\n",
    "        print(\"filtering stationid\")\n",
    "        temp = temp[temp[\"StationId\"].apply(lambda x: x[0:2]) == \"US\"]\n",
    "        print(\"filtering measurements\")\n",
    "        temp = temp[temp[\"Measurement\"].apply(lambda x: x in desired_measurements)]\n",
    "        print(\"dropping columns\")\n",
    "        temp = temp.drop(columns = [\"Flag1\", \"Flag2\", \"Flag3\", \"Flag4\"])\n",
    "        print(\"joining coords\")\n",
    "        temp = pd.merge(temp, us_station_codes, on = \"StationId\")\n",
    "        print(\"exporting\")\n",
    "        temp.to_csv(file[0:4] + \"_filtered.csv\")\n",
    "        \n",
    "\n",
    "print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5bc07",
   "metadata": {},
   "source": [
    "# EPA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e53e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPA_Zip_Files = os.listdir(EPA_dir + r\"\\\\Raw EPA Data\")\n",
    "EPA_Zip_Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927f638",
   "metadata": {},
   "source": [
    "### Testing first with Ozone 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13253feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ozone_1989 = pd.read_csv(EPA_dir + r\"\\\\Raw EPA Data\\\\\"  + EPA_Zip_Files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone_1989.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique identifier per air quality station based on State Code, County Code, and Site Num\n",
    "def create_ozone_id(statelist, countylist, sitelist):\n",
    "    \"\"\"\n",
    "    Helper function for creating ozoneID's based on an EPA dataset\n",
    "    \n",
    "    returns: 3 lists appended together into tuples to be added into a column\n",
    "    \"\"\"\n",
    "    return [(a,b,c) for a, b, c in zip(statelist, countylist, sitelist)]\n",
    "\n",
    "def append_ozone_id(ozone_df):\n",
    "    \"\"\"\n",
    "    Creates a copy of the dataframe and adds a new column that concatenates the state code, county code, and site number\n",
    "    into a tuple to make an individual identifier for each ozone reporting location in that year. \n",
    "    \n",
    "    returns: dataframe with ozoneID\n",
    "    \"\"\"\n",
    "    temp = ozone_df.copy() \n",
    "    temp[\"ozoneID\"] = create_ozone_id(temp[\"State Code\"], temp[\"County Code\"], temp[\"Site Num\"])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone_1989 = append_ozone_id(ozone_1989)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53eaa29",
   "metadata": {},
   "source": [
    "# Joining EPA data with NOAA data\n",
    "\n",
    "- First need to figure out the 10 closest weather stations for each EPA ozone location (PER YEAR, might have different ozone stations over time) \n",
    "\n",
    "- Save these closest weather stations in a dictionary so that we can access it in the future (save as a dictionary based on ozoneID\n",
    "\n",
    "Run a for loop across each iteration of the EPA data and create data dictionaries for each individual index in the EPA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7241bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ozoneID_coords(ozone_df):\n",
    "    \"\"\"\n",
    "    Groups entire dataframe by ozoneID and then applies lambda function that extracts the first entry of Latitude, Longitude\n",
    "    \n",
    "    returns: a series indexed by ozoneID that gives back information that can then be indexed into using key's 'Latitude' and\n",
    "    'Longitude'\n",
    "    \n",
    "    NOTE: WE CAN GET ALL UNIQUE OZONE ID FROM THIS OUTPUT'S INDEX using output.index\n",
    "    \"\"\"\n",
    "    #first check that the required columns are there, otherwise print an error\n",
    "    if all(column in ozone_df.columns for column in [\"ozoneID\", \"Latitude\", \"Longitude\"]):\n",
    "        return ozone_df.groupby(\"ozoneID\").apply(lambda gr: gr[[\"Latitude\", \"Longitude\"]].iloc[0,:])\n",
    "    else:\n",
    "        raise Exception(\"one of the columns needed in ozoneID, Latitude, Longitude was missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make a dictionary after finding the closest weather station and then figure out from there \n",
    "lat_long_ozone_1989 = ozone_1989.groupby(\"ozoneID\").apply(lambda gr: gr[[\"Latitude\", \"Longitude\"]].iloc[0,:])\n",
    "lat_long_ozone_1989"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de93595",
   "metadata": {},
   "source": [
    "For every observation location we get their longitude and latitude and calculate the vincenty distance to all of the weather stations and then sort data frame by distance and return top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vincenty import vincenty_inverse\n",
    "\n",
    "def get_closest_stations(lat_long_pair):\n",
    "    print(\"working on \" + str(lat_long_pair))\n",
    "    temp = us_station_codes.copy()\n",
    "    temp[\"ozone_lat\"] = lat_long_pair[\"Latitude\"]\n",
    "    temp[\"ozone_long\"] = lat_long_pair[\"Longitude\"]\n",
    "    temp[\"vincenty_dist\"] = [vincenty_inverse((a, b), (c, d)) for a, b, c, d in zip(temp[\"lat\"], \n",
    "                                                                            temp[\"long\"], \n",
    "                                                                            temp[\"ozone_lat\"], \n",
    "                                                                            temp[\"ozone_long\"])]\n",
    "    sorted_distances = temp.sort_values(\"vincenty_dist\")[[\"StationId\",\"vincenty_dist\"]].iloc[0:10, :]\n",
    "    return sorted_distances.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0d42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_stations = {}\n",
    "for ozone_station in lat_long_ozone_1989.index:\n",
    "    ozone_station_coord = lat_long_ozone_1989[ozone_station]\n",
    "    closest_stations[ozone_station] = get_closest_stations(ozone_station_coord)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975f738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b8194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(closest_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"closest_stations_1989.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest stations maps each ozone code to a specific weather station based on longitude and latutude\n",
    "closest_1989 = pd.read_csv(\"closest_stations_1989.csv\", header = [0,1,2], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb217a10-fc18-4916-9cf5-da6d5342b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_1989.to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
